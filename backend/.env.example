# Application
APP_ENV=development
DEBUG=true
API_HOST=0.0.0.0
API_PORT=8000

# Database (Supabase Free Tier)
DATABASE_URL=postgresql://user:password@localhost:5432/interview_assistant
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-supabase-anon-key

# Local LLM (Ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Whisper
WHISPER_MODEL_SIZE=base
WHISPER_DEVICE=cpu

# AWS (Free Tier)
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=your-access-key
AWS_SECRET_ACCESS_KEY=your-secret-key
S3_BUCKET_NAME=interview-assistant-artifacts

# Feature Flags
ENABLE_HALLUCINATION_CHECK=true
ENABLE_BODY_LANGUAGE=true
ENABLE_CODE_EXECUTION=true

# Judge0 Configuration
JUDGE0_API_KEY=your_rapidapi_key_here
JUDGE0_USE_HOSTED=false  # Set to false for local Docker instance
JUDGE0_BASE_URL=http://localhost:2358

# Hugging Face API Token (for Vision-LLM)
# Get free token from: https://huggingface.co/settings/tokens
# HF token must have the "Make calls to Inference Providers" permission enabled in your token settings. 
HF_TOKEN=your_hugging_face_token_here